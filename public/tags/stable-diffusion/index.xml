<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Stable Diffusion on yadnyesh&#39;s blog</title>
    <link>http://localhost:1313/tags/stable-diffusion/</link>
    <description>Recent content in Stable Diffusion on yadnyesh&#39;s blog</description>
    <generator>Hugo -- 0.147.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Apr 2025 12:34:29 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/stable-diffusion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Go With The Flow</title>
      <link>http://localhost:1313/posts/go_with_the_flow/</link>
      <pubDate>Sun, 27 Apr 2025 12:34:29 +0530</pubDate>
      <guid>http://localhost:1313/posts/go_with_the_flow/</guid>
      <description>&lt;p&gt;Flow-based generative models are starting to turn heads as a cool alternative to traditional diffusion methods for things like image and audio generation. What makes them stand out is how they learn smooth, efficient paths to transform one distribution into another—basically a neat and mathematically solid way to generate data. They’ve been getting a lot more buzz lately, especially after Black Forest Labs dropped their &lt;a href=&#34;https://bfl.ai/models/flux-pro&#34;&gt;FLUX&lt;/a&gt; models and &lt;a href=&#34;https://stability.ai/news/introducing-stable-diffusion-3-5&#34;&gt;SD3.5&lt;/a&gt; model by Stability AI. That success has brought fresh attention to the earlier ideas behind Rectified Flows, which first popped up at ICLR 2023.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
